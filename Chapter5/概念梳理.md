# 优化程序性能

> 专注于梳理本章中出现的重要概念，对概念的描述尽量做到述而不作，避免因为个人理解偏差对其他人造成误导。
>
> 本章主要介绍如何使用几种不同类型的程序优化技术，在程序运行正确的基础上，使程序运行的更快。

* 编写高效程序的方法论

  * 选择一组适当的数据结构和算法
  * 必须编写出编译器能够有效优化以转换成高效可执行代码的源代码，理解编译器的能力和局限性很重要（比如C语言中执行指针运算和强制类型转换就很难被编译器优化）
  * 针对处理运算量特别大的计算，将一个任务分成多个部分，这些部分可以在多核和多处理器的某种组合上并行的计算

* 妨碍优化的因素（optimization blocker）

  程序行为中那些严重依赖于执行环境的方面，比如可能出现的内存别名使用、函数调用等。

* 汇编代码 VS 重写程序

  使用汇编代码，固然也可以达到优化程序性能的目的，但是汇编代码具有比较强的平台依赖性，不容易移植。相比于另一种方法，不断重写程序直到编译器由此可以产生有效的代码为止，虽然性能不一定是最好的，但是得到的代码可以在其他机器上运行。

* 现实中，对代码的优化不是一帆风顺的

  优化需要很多的试错实验，一些看上去很小的变化会导致性能上很大的变化，而性能可能依赖于处理器设计的许多细节特性，对此我们所知甚少，所以要想让编译器尽可能的产生有效代码，需要

  * 尝试各种技术的变形和组合
  * 理解编译器产生的汇编代码，在此基础上，修改源代码
  * 循环修改代码，分析性能，使编译产生的代码尽可能的好



## 优化编译器的能力和局限性

* 编译器提供的优化控制

  现代编译器运用复杂精细的算法来确定一个程序中计算的是什么值，以及它们是如何被使用的，然后会利用一些机会来简化表达式。

  大多数编译器，向用户提供了一些对它们所使用的优化的控制，最简单的优化控制优化级别，比如`-Og`、`-O1`、`-O2`等。

* 安全的优化

  对于程序可能遇到的所有可能的情况，保证优化后得到的程序和未优化的版本有一样的行为。

  编译器只对程序进行安全的优化，在优化过程中，考虑妨碍优化的因素。

  * 内存别名使用

    程序中的两个指针可能指向同一个内存位置。如果编译器不能确定两个指针是否指向了同一个位置，就必须假设什么情况都有可能，这就限制了可能的优化策略。

  * 函数调用

    函数的执行过程中可能会修改全局程序状态的一部分，改变调用函数的次数会改变程序的行为，所以大多数编译器不会试图判断一个函数是否没有副作用，而会直接假设是最糟的情况，并保持所有函数的调用不变。

* 用**内联函数替换**（inline substitution）优化函数调用

  直接将函数调用替换成函数体本身。这样转换既减少了函数调用的开销，也允许对展开代码做进一步的优化。

  在GCC中，可以使用命令行选项`-finline`指示，或者使用优化等级`-O1`及以上，但是GCC只尝试在单个文件中定义的函数的内联，也就是说它无法处理一组库函数在一个文件中被定义，却被其他文件内的函数所调用。

  不过使用内联函数替换会影响符号调试器追踪或者设置断点。

## 表示程序性能

* 时钟频率/时钟周期

  通常用千兆赫兹（GHz）来表示，即十亿周期每秒，比如一个系统有”4GHz“处理器，这表示处理器时钟运行频率为每秒$4\times 10^9$个周期，每个周期的时间是时钟频率的倒数。

* 每元素的周期数（Cycles Per Element, CPE）

  以”前缀和“为例，随着运算的数据规模的增加，一个过程所需要的时间（以时钟周期为单位）可以用一个常数加上一个与被处理元素个数成正比的因子来描述，这个系数就是CPE的有效值。

## 程序示例

* C语言里面的宏定义`#define`真的很强啊，以前都不知道还可以直接定义操作的，例如

  ```c
  #define OP +
  int main() {
    int a = 1;
    int b = 2;
    int c = a OP b;
    printf("%d\n", c);
  }
  ```

* 养成使用编译器的级别优化是一个好习惯

  未经优化的代码是从C语言到机器代码的直接翻译，通常效率明显比较低，简单的使用命令行选项`-O1`，就会进行一些基本的优化，程序员不需要做什么，就可以达到一定的优化效果。
  
* 一个优化示例

  使用某种运算，将一个向量中所有的元素合并成一个值。通过使用编译时常数IDENT和OP的不同定义，该代码可以重新编译成对数据执行不同的运算。下面是`combine1`的代码，书中后面提到的优化方案都是基于这个代码做实验的。

  ```c
  #define OP +
  #define IDENT 0
  void combine1(vec_ptr v, data_t *dest) {
  	 long i;
  	 *dest = IDENT;
  	 for (i = 0;i < vec_length(v);i++) {
  	 	data_t val;
  	 	get_vec_element(v, i, &val);
  	 	*dest = *dest OP val;
  	 }
  }
  ```

## 消除循环的低效率

* 代码移动（code motion）

  比较常见的优化方法，这类优化包括识别要执行多次（例如在循环里）但是计算结果不会改变的计算，将计算移动到代码前面不会被多次求值的部分。

  优化编译器虽然会试着进行代码移动，但是对于会改变在哪里调用函数或调用多少次的变换，编译器通常会非常小心。它们不能可靠地发现一个函数是否会有副作用，因而假设函数会有副作用。

  ```c
  /* 把调用vec_length函数移动到循环外 */
  void combine2(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    
    *dest = IDENT;
    for (i = 0; i < length;i++) {
      data_t val;
  	 	get_vec_element(v, i, &val);
  	 	*dest = *dest OP val;
    }
  }
  ```

* 库函数strlen的实现

  虽然strlen通常是用特殊的x86字符串处理指令来实现的，但是它的整体执行还是需要一步一步检查整个序列，直到碰到结尾的null为止。如果在一个循环体中以调用`strlen()`函数作为判断停止的条件，那么会使得整体运行时间变成字符串长度的二次项。

## 减少过程调用

* 以从数组中读取指定下标的元素为例

  如果通过调用一个函数来获取指定元素，那每次都需要把索引和循环边界做比较。如果按顺序访问数组中的元素，且明确不会越界，那么每次做判断会导致低效率。（但是因为其他一些限制因素，这样修改后没有带来太大的性能提升）

  ```c
  data_t *get_vec_start(vec_ptr v) {
    return v->data;
  }
  
  /* 直接访问数组元素 */
  void combine3(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);
    
    *dest = IDENT;
    for (i = 0; i < length;i++) {
  	 	*dest = *dest OP data[i];
    }
  }
  ```

## 消除不必要的内存引用

* 在累积求值时，不需要每次都把中间结果写到内存中，读/写内存的开销是很大的。

  ```c
  /* 在局部变量中进行结果的累加 */
  void combine4(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);
    data_t acc = IDENT;
    
    for (i = 0; i < length;i++) {
  	 	acc = acc OP data[i];
    }
    *dest = acc;
  }
  ```

  给编译器加优化编译参数，并不会对`combine3`中的内存访问进行自动优化，因为可能存在之前所说的内存别名问题，比如若定义`dest=get_vec_start(v) + 2`，调用`combine3`和`combine4`会产生不一样的结果。

## 理解现代处理器

> 以上的优化方案不依赖于目标机器的任何特性，这些优化只是简单地降低了过程调用的开销，消除了一些重大的”妨碍优化的因素“，尽可能的帮助编译器，使其能生成高性能代码。

* 指令级并行

  在代码级别看上去是一次执行一条指令，每条指令都包括从寄存器或内存取值，执行一个操作，并把结果存回到一个寄存器或内存位置。在实际的处理器中，是同时对多条指令求值的。现代微处理器保证多条指令可以并行地执行，同时又呈现出一种简单的顺序执行指令的表项。

* 延迟界限和吞吐量界限

  这两种下界描述了程序的最大性能。

  * 当一系列操作必须按照严格顺序执行时，就会遇到延迟界限（latency bound）。下一条指令开始之前，这条指令必须结束，代码中的数据相关限制了处理器利用指令级并行的能力时，延迟界限能够限制程序性能。

    延迟界限给出了任何必须按照严格顺序完成合并运算的函数所需要的最小CPE的值（就是某个的操作的延迟）

  * 吞吐量界限（throughput bound）刻画了处理器功能单元的原始计算能力，这个界限是程序性能的终极限制。

    根据功能单元产生结果的最大速率，吞吐量界限给出了CPE的最小界限，比如四个功能单元都可以执行整数加法，处理器有可能持续每个周期执行4个操作的速率，但是两个加载单元限制了处理器每个时钟周期最多能读取两个数据值，故这种情况下吞吐量界限为0.5。

* 超标量（superscalar）

  一种处理器的设计方式，在每个时钟周期都可以乱序的执行多个操作，指令执行的顺序不一定要与它们在机器级程序中的顺序一致。整个设计有两个主要部分：

  * 指令控制单元（Instruction Control Unit，ICU）

    ICU从指令高速缓存（instruction cache，特殊的高速存储器包含最近访问的指令）中读取指令。通常会在当前执行的指令很早之前就取值，这样才有足够的时间对指令译码。对于存在分支无法判断前进方向的时候，可以采用

    * 使用分支预测（branch prediction）的技术，处理器猜测是否会选择分支，同时还预测分支的目标地址。使用投机执行（speculative prediction）的技术，处理器会取出位于它预测的分支会跳到的地方的指令，并对指令译码，甚至开始提前执行。
    * 采用以上方法，一旦后面发现分支预测错误，会将状态重新设置到分支点的状态，并开始取出和执行相反方向的指令。
    * ICU中的”取值控制“块包括分支预测，负责确定取哪些指令。

    ICU中的”指令译码“逻辑负责接收实际的程序指令，并将它们转换成一组基本操作。一条复杂的指令可以被译码成多个操作，这个不同的机器都不大相同。

    ICU中的“退役单元”记录正在进行的处理，并确保它遵守机器级程序的顺序的语义。如图所示其内部包括一个寄存器文件，它包含整数、浮点数和最近的SSE和AVX寄存器，退役单元会控制这些寄存器的实际更新。指令译码阶段，关于指令的信息被放置在一个先进先出的队列中，这个信息会一直保持在队列中，直到：

    * 一条指令的操作完成了，而且所有引起这条指令的分支点也都被确认为预测正确，那么这条指令就可以退役了，所有对程序寄存器的更新都可以被实际执行了。
    * 如果引起该指令的某个分支点预测错误，这条指令会被清空，丢弃所有计算出来的结果。

  * 执行单元（Execution Unit，EU）

    * EU接收来自取值单元的操作，每个时钟周期会接收多个操作，这些操作会被分派到一组功能单元中，不同的功能单元负责不同类型的操作。

    * 执行过程中读写内存是由加载和存储单元实现的，对地址的计算由加法器完成，通过数据高速缓存（高速存储器，存放最近访问的数据值）来访问内存。

    * 使用投机执行技术对操作数求值的结果不会放在程序寄存器或者数据内存中，直到确定对指令的预测是正确。若预测错误，EU会丢弃分支点之后计算出来的结果，并发信号给分支单元，说明预测错误，并指出正确的分支目的，至此分支单元会反作用于取指控制，重新取指。

    * 随着技术的发展，功能单元的数量，每个单元能执行的操作的组合以及每个单元的性能都有所增加。以Intel Core i7 Haswell参考机有8个功能单元为例，它有4个功能单元可以执行整数操作，2个功能单元可以执行加载操作，2个功能单元可以执行浮点乘法。

      | 编号 |                单元的功能                |
      | :--: | :--------------------------------------: |
      |  0   | 整数运算、浮点乘、整数和浮点数除法、分支 |
      |  1   |     整数运算、浮点加、整数乘、浮点乘     |
      |  2   |              加载、地址计算              |
      |  3   |              加载、地址计算              |
      |  4   |                   存储                   |
      |  5   |                 整数运算                 |
      |  6   |              整数运算、分支              |
      |  7   |              存储、地址计算              |

  * 寄存器重命名

    通用的技术用于控制操作数在执行单元间传送。当一条更新寄存器r的指令译码时，产生标记t，得到一个指向该操作结果的唯一的标识符。条目（r，t）被加入到一个表中。当随后以寄存器r作为操作数的指令译码时，发送到指令单元的操作会包含t作为操作数源的值。当某个执行单元完成第一操作时，会生成一个结果（v，t），指明标记为t的操作产生值v，所有等待t作为源的操作都能使用v作为源值，这就是一种形式的数据转发。（值可以从一个操作直接转发到另一个操作，而不是写到寄存器文件再读出来）

  <img src="images/乱序处理器.png" alt="乱序处理器" style="zoom:67%;" />

  

* 功能单元的性能描述

  * 延迟：完成运算需要的总时间
  * 发射时间：两个连续的同类型的运算之间需要的最小时钟周期数
  * 容量： 能够执行该运算的功能单元的数量

* 完全流水线化

  流水线化的功能单元，实现为一系列的阶段，每个阶段完成一部分的运算，算术运算可以连续地通过各个阶段，而不同等待一个操作完成后再进行下一个，这种发射时间为1的功能单元被称为完全流水线化的。（除法器不是完全流水线化的）

* 最大吞吐量（发射时间的倒数）

  一个完全流水线化的功能单元有最大的吞吐量，每个时钟周期一个运算，发射时间较大的功能单元的最大吞吐量比较小，具有多个功能单元可以进一步提供吞吐量。

  对于一个容量为C，发射时间为I的操作来说，处理器可能获得的吞吐量为每时钟周期$C/I$个操作。

* 程序的数据流

  是一种图形化表示方法，作为分析现代处理器上执行的机器级程序性能的一个工具，展现了不同操作之间的数据相关是如何限制它们的执行顺序的。

* 关键路径

  因为不同的操作之间可能存在数据相关，会限制执行的顺序，故将执行一组机器指令所需时钟周期数的一个下界称为关键路径。

* 以前面`combine4`的代码为例，说明从机器级代码到数据流图

  ```
  combine4的内部循环，data_t=double，OP=*
  acc放在%xmm0，data+i放在%rdx，data+length放在%rax
  .L25
  	vmulsd (%rdx), %xmm0, %xmm0
  	addq $8, %rdx
  	cmpq %rax, %rdx
  	jne .L25
  ```

  * 指令译码器将上面的四条指令扩展成为一系列的五步操作，最开始的乘法指令被扩展成为一个load操作，从内存读出源操作数，和一个mul操作，执行乘法。

  * 生成程序数据流图表示的第一步，给出各个指令是如何使用和更新寄存器的，顶部的方框表示循环开始时寄存器的值，而底部的方框表示最后寄存器的值。某些操作产生的值不对应于任何寄存器，用操作间的弧线表示。

    <img src="images/程序数据流1.png" alt="程序数据流1" style="zoom:67%;" />

  * 对于形成循环的代码片段，可以将访问到的寄存器分为四类

    * 只读：只作为源值，在循环中它们不会被修改
    * 只写：作为数据传送操作的目的
    * 局部：寄存器在循环内部被修改和使用，迭代与迭代之间不相关（比如条件码寄存器）
    * 循环：对于循环来说，这些寄存器既作为源值，又作为目的，一次迭代中产生的值会在另一次迭代中用到。（%xmm0和%rdx）

    循环寄存器之间的操作链决定了限制性能的数据相关。

  * 对以上数据流图进行改进，只给出影响程序执行时间的操作和数据相关。重新排列操作符，如果操作符不属于某个循环寄存器之间的相关链，则标识为白色。最后只保留循环寄存器，得到的是一个抽象的模板，表明的是由于循环一次迭代在循环寄存器中形成的数据相关。

    <img src="images/程序数据流2.png" alt="程序数据流2" style="zoom:67%;" />

  * 最后得到n次迭代的数据流表示，从图中可以看出，程序有两条数据相关链，分别对应add和mul操作，假设浮点数乘法的延迟大于整数的加法，那么左边的链（mul）会成为关键路径。

    <img src="images/关键路径.png" alt="关键路径" style="zoom:67%;" />

  * 数据流表示中的关键路径提供的只是程序需要周期数的下界，还有一些其他因素会限制性能。

  * `combine4`程序的性能分析，其关键路径长$L \times n$是由于对程序值acc的连续更新造成的，这条路径将CPE限制为最多L，目前该程序的CPE由延迟界限决定。

## 循环展开

* 循环展开

  一种程序变换，通过增加每次迭代计算的元素的数量，减少循环的迭代次数。可以从两个方面改进程序的性能：

  * 减少了不直接有助于程序结果的操作的数量，比如循环索引计算和条件分支
  * 提供了一些方法，可以进一步变化代码，减少整个计算中关键路径上的操作数量

* 在累积求值时，使用$2\times 1$的循环展开

  ```c
  void combine5(vec_ptr v, data_t *dest) {
  	long i;
  	long length = vec_length(v);
  	long limit = length - 1;
  	data_t *data = get_vec_start(v);
  	data_t acc = IDENT;
  	
  	for (i = 0; i < limit; i += 2) {
  		acc = (acc OP data[i]) OP data[i + 1];
  	}
  	
  	/* 处理余下的元素 */
  	for (; i < length; i++) {
  		acc = acc OP data[i];
  	}
  	*dest = acc;
  }
  ```

  可以将这个思想归纳为对一个循环按任意因子k进行展开，由此产生$k \times 1$循环展开，为此，上限设为$n-k+1$，在循环内对元素$i$到$i+k-1$应用合并计算。在第二个循环中处理剩余的元素，这个循环将被执行$k-1$次。

  通过循环展开，减少了循环开销操作，也就是上面所说的其他因素，此时，一个周期的延迟成为限制性能的主要因素。

  在这里，只是简单的循环展开，不涉及变化代码，减少关键路径上的操作数量。

  ![循环展开后的关键路径](images/循环展开后的关键路径.png)

## 提高并行性

> 硬件具有以更高速率（完全流水线化，多个功能单元）执行乘法和加法的潜力，但是目前的代码包括循环展开都不能利用这种能力，把累积值放在一个变量中，限制了并行性。

* 多个累积变量

  在累积求值时，使用$2\times 2$的循环展开，既使用两次循环展开，使每次迭代合并更多的元素，也使用两路并行，将索引值为偶数的元素和索引值为奇数的元素分别累积在不同的变量中。

  ```c
  void combine6(vec_ptr v, data_t *dest) {
  	long i;
  	long length = vec_length(v);
  	long limit = length - 1;
  	data_t *data = get_vec_start(v);
  	data_t acc0 = IDENT;
  	data_t acc1 = IDENT;
  	
  	for (i = 0; i < limit; i += 2) {
  		acc0 = acc0 OP data[i];
  		acc1 = acc1 OP data[i + 1];
  	}
  	
  	/* 处理余下的元素 */
  	for (; i < length; i++) {
  		acc = acc OP data[i];
  	}
  	*dest = acc0 OP acc1;
  }
  ```

  虽然这个内循环中依然包含两个`vmulsd`运算，但是这些指令被翻译成读写不同寄存器的mul操作，它们之间没有数据相关。此时，计算索引为偶数的元素的乘积和计算索引为奇数的元素的乘积分别是两条关键路径，每个关键路径只包含$n/2$个操作，从而对应CPE的理论值也会减半。

  ![循环展开并行累积后的关键路径](images/循环展开并行累积后的关键路径.png)

  更具一般性的说，可以将多个累积变量变换归纳为将循环展开k次，以及并行累积k个值，得到$k \times k$循环展开，当k足够大的时候，程序在所有情况下几乎都能达到吞吐量界限。

  对完全流水线化的操作（发射延迟为1），只有保持能够执行该操作的所有功能单元的流水线都是满的，程序才能达到这个操作的吞吐量界限，对延迟为L，容量为C的操作而言，这就要求循环展开因子$k \ge C \times L$。

  另外在进行并行累积时，需要考虑到所进行的运算是否具有可结合和可交换性，比如进行整数运算时combine5和combine6会得到一样的结果，但由于浮点数运算不是可结合的，由于四舍五入或溢出会导致combine5和combine6的结果不一样。

* 重新结合变化

  改变向量元素和累计值acc的合并顺序，称为$2\times 1a$的循环展开形式。

  ```c
  void combine5(vec_ptr v, data_t *dest) {
  	long i;
  	long length = vec_length(v);
  	long limit = length - 1;
  	data_t *data = get_vec_start(v);
  	data_t acc = IDENT;
  	
  	for (i = 0; i < limit; i += 2) {
  		acc = acc OP (data[i] OP data[i + 1]);
  	}
  	
  	/* 处理余下的元素 */
  	for (; i < length; i++) {
  		acc = acc OP data[i];
  	}
  	*dest = acc;
  }
  ```

  测试以上代码产生的结果，发现整数加的性能几乎和使用$k\times1$展开版本的性能相同，而其他三种情况则与使用并行累积变量的版本相同，已经突破了延迟界限造成的限制。

  虽然还是有两个mul操作，但是只有一个mul操作形成了循环寄存器间的数据相关链（和累积变量acc相乘的操作），故关键路径上只有$n/2$个操作。
  ![重新结合变化后的关键路径](images/重新结合变化后的关键路径.png)

  同样的，当k足够大时，实现$k\times 1a$带来的性能提升和$k\times k$类似，都接近由功能单元造成的吞吐量界限。不过也需要考虑改变运算顺序对浮点数运算的影响。

* 向量化指令

  SSE（Streaming SIMD Extensions）的最新版本为AVX（advanced vector extension），所谓SIMD执行模型是用单指令对整个向量数据进行操作，这些向量保存在一组特殊的向量寄存器中，目前的AVX向量寄存器长为32字节，因此每一个都可以存放8个32位数或4个64位数，AVX指令可以对这些寄存器执行向量操作，从而一条指令可以对多个数据值进行计算。

  GCC支持对C语言的扩展，能够让程序员在程序中使用向量操作，这些操作能够被编译成AVX的向量指令。

  使用向量化指令对合并操作产生了新的吞吐量界限，与标量界限相比，32位操作的新界限小了8倍，64位操作的新界限小了4倍。

## 一些限制因素

> 除了关键路径和功能单元的吞吐量限制外，其他的一些制约程序在实际机器上性能的因素。我们已经知道会影响程序性能的因素
>
> * 如果程序中有某条数据相关链，这条链上的所有延迟之和等于T，那么这个程序至少需要T个周期才能完成。
> * 假设一个程序一共需要N个某种运算的计算，而微处理器只有C个能执行这个操作的功能单元，并且这些单元的发射时间为I，那么这个程序的执行至少需要$\frac{NI}{C}$个周期。

* 寄存器溢出

  循环并行性的好处受汇编代码描述计算的能力限制，如果并行度超过了可用寄存器的数量，那么编译器会将某些临时值存放在内存中，通常在运行时堆栈上分配空间，也就是说随着循环展开程度的增加，并不总是会改善CPE，一旦编译器必须要诉诸寄存器溢出，那么维护多个累积变量的优势就很可能会消失。

* 分支预测和分支错误惩罚

  当分支预测逻辑不能正确预测一个分支是否要跳转的时候，条件分支可能会招致很大的预测错误处罚。

  * 在投机执行的处理器中，处理器会开始执行预测的分支目标处的指令，但会避免修改任何实际的寄存器或内存位置，直到确定了实际的结果。如果预测正确，提交投机执行的指令的结果，如果预测错误，则必须丢掉所有投机执行的结果，在正确的位置，重新开始取指令的过程，这样就需要重新填充指令流水线。
  * 相比于传统的基于控制的条件转移的实现，通过计算条件表达式两个方面的值，然后用条件传送指令选择期望的值更好一些，条件传送指令可以被实现为普通指令流水线化处理的一部分，没有必要猜测条件是否满足，因此猜测错误也没有处罚。

  如何保证分支预测处罚不会阻碍程序的效率？

  * 不要过分关心可预测的分支

    虽然错误的分支预测的影响可能会非常大，但是不是说所有的程序分支都会减缓程序的执行，现代处理器中的分支预测逻辑非常善于辨别不同的分支指令的有规律的模式和长期的趋势。

    所以前面combine3减少每次把索引和循环边界做比较的操作，并没有对程序造成比较明显的改善，因为这个操作本身是高度可预测的。

  * 书写适合用条件传送实现的代码

    对于本质上完全无法预测的情况，如果编译器能够产生使用条件数据传送而不是使用条件控制转移的代码，可以极大的提高程序的性能。

    GCC能够为以一种更为“功能性的”风格书写的代码产生条件传送，其实就是条件选择语句。

    ```c
    long min = a[i] < b[i] ? a[i] : b[i]
    ```

    但不是所有的条件行为都能用条件数据传送来实现，如果不可避免的写出导致条件分支的语句，那么处理器用分支预测可能会处理很糟糕。通常的方法是，写出函数的不同版本，检查产生的汇编代码，并测试性能。

## 理解内存性能

> 所有现代的处理器都包含一个或多个高速缓存（cache）存储器，可以对这样少量的存储器提供快速的访问。研究涉及加载和存储操作的程序性能，只考虑所有程序都存放在高速缓存中的情况。

* 加载的性能

  如果有两个加载单元，对于每个被计算的元素必须加载k个值的应用，不可能获得低于$k/2$的CPE。

* 存储的性能

  一系列存储操作不会产生数据相关，但加载和存储操作之间可能会相互影响。

  * 写/读相关

    一个内存读的结果依赖于一个最近的内存写，在这种情况下，程序运行的相对会比较慢。

* 加载和存储单元

  存储单元包含一个存储缓冲区，它包含已经被发射到存储单元而又还没有完成（包含更新数据高速缓存）的存储操作的地址和数据，有缓冲区使得一系列存储操作不必等待每个操作都更新高速缓存就能够执行。

  当一个加载操作发生时，它必须检查存储缓冲区中的条目，看有没有地址相匹配的，地址相匹配意味着写的字节与在读的字节有相同的地址，它就取出相应的数据条目作为加载操作的结果，以发现写/读相关。

  <img src="images/加载存储单元细节.png" alt="加载存储单元细节" style="zoom:80%;" />

* 一个程序示例

  ```c
  void write_read(long *src, long *dst, long n) {
  	long cnt = n;
  	long val = 0;
  	while (cnt) {
  		*dst = val;
  		val = (*src) + 1;
  		cnt--;
  	}
  }
  ```

  其内循环对应的汇编代码：

  ```
  src in %rdi, dst in %rsi, val in %rax
  .L3
  	movq %rax, (%rsi)
  	movq (%rdi), %rax
  	addq $1, %rax
  	subq $1, %rdx
  	jne .L3
  ```

  其中将`movq %rax, (%rsi)`翻译成两个可以独立计算的指令

  * s_addr指令，计算存储操作的地址，在存储缓冲区创建一个条目，并设置该条目的地址字段。
  * s_data指令，设置该条目的数据字段

  如图所示，是该程序的数据流图，其中的虚弧线是有条件的数据相关，如果两个操作地址相同，则load操作必须等待直到s_data将它的结果放入缓冲区，否则两个操作可以独立执行。

  <img src="images/存储程序数据流1.png" alt="存储程序数据流1" style="zoom:67%;" />

  对write_read操作进行抽象重新排列，标出三个涉及加载和存储操作的相关：

  * 存储地址必须在数据被存储之前计算出来
  * load操作需要将它的地址和所有未完成的存储操作的地址进行比较
  * 虚弧线表示条件数据相关，当加载和存储地址相同时出现

  <img src="images/存储程序数据流2.png" alt="存储程序数据流2" style="zoom:80%;" />

  从上图中也可以看出，有两个相关链，左边的是存储、加载和增加数据值（只在地址相同时有效），右边是减少变量cnt。

  所以可以说，当使用不同的源和目的地址时，关键路径如左图所示，是由减少变量cnt形成的；当源和目的地址相同时，s_data和load指令之间的数据相关使得关键路径的形成包含了存储、加载和增加数据，顺序执行这三个操作，会造成性能的下降。

  ![存储关键路径](images/存储关键路径.png)

* 寄存器操作和内存操作的区别

  对于寄存器操作，在指令被译码成操作的时候，处理器就可以确定指令之间的相关关系，但对于内存操作来说，只有到计算出加载和存储的地址后，处理器才能确定指令之间是否互相影响。

## 应用：性能提高技术

* 总结以上提出的，如何优化程序性能的基本策略：

  * 高级设计

    * 为遇到的问题选择适当的算法和数据结构。

  * 基本编码原则

    避免限制优化的因素，使编译器能产生高效的代码

    * 消除连续的函数调用
    * 消除不必要的内存引用

  * 低级优化

    * 展开循环，降低开销
    * 通过类似多个累积变量和重新结合的技术，提高指令级并行
    * 用功能性的风格重写条件操作，使编译采用条件数据传送。

* 在优化程序性能时，要保证程序的正确性，和一系列的边界测试。